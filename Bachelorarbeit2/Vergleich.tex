Beide Algorithmen gehen nach dem gleichen Prinzip vor - das größte Erweiterbare Element zu finden, und dann erweitert einzusetzen. $prev$ und $RMaxQ$ sind in der Funktionsweise also äquivalent - unabhängig von der Datenstruktur. Genauso verwalten beide Algorithmen ein Array für die Rekonstruktion und löschen Elemente, die größer als $prev$ sind, aber im $score$ kleiner als das Neue. Der einzige fassbare Unterschied ist die Reihenfolge, also ob zuerst eingefügt, dann gelöscht wird, oder andersrum. Im Original vom Kapitel $4$ wird zusätzlich ein $(0,0)$ und $(\infty,\infty)$ eingefügt, damit nicht auf $\phi$ überprüft werden muss. Das ist aber eine Frage der Implementierung bzw. Programmierstil, und nicht des Algorithmus'.\\
$"$Note that the Algorithm 8.4 maintains the following invariant: If $q1 < q2 < ··· < ql$ are the entries in the data structure D, then $q1.score \leq q2.score \leq ··· \leq ql.score$.$"$\cite{ohlebusch}- dies beschreibt die Ordnung der Elemente in D. Interessanterweise können aber keine zwei Elemente mit gleichem $score$ in $D$ sein nach Zeile $8$ und $10$. Für den DP Algorithmus gilt $"$We maintain the invariant that L is strictly increasing in both coordinates. Therefore, the ordering based on their first coordinate (the alphabet ordering) can be used to order L. Figure 2 shows the HIS algorithm.$"$\cite{schensted1961longest}. Also auch eine strenge Monotonie der Elemente. Das bedeutet, dass die gleichen Elemente eingefügt und gelöscht werden müssen in einer Iteration, damit die Anforderungen erfüllt bleiben. Einzig in der Frage wie man mit einen Element, welches eingefügt werden soll, umgehen soll, dessen $score$ schon in $D$ Liste, unterscheiden sich die Algorithmen. Der DP Algorithmus löscht so ein Element und fügt das neue ein, dieser Algorithmus verändert D nicht. Wenn man im DP Algorithmus Zeile 15 in $if(v+a_i)\leq w$ umwandelt und in Zeile $16$ ein $continue$ statt $break$ hat, ergibt sich das gleiche Prinzip. Beide Algorithmen unterscheiden sich also minimal in der Vorgehensweise.\\
Da nach dem Gesetz der großen Zahlen es zufällig ist, wie der $score$ für ein Element aussieht, ist der Nutzen direkt abhängig davon, wie viele Elemente mit gleichem $score$ eingefügt werden. Man kann aber wie den DP Algorithmus auch diesen mit einem FT und kriegt dann einen abgewandelten Quellcode, der identisch dem vom DP Algorithmus ist. Die Laufzeitanalyse und Korrektheit ist nahezu identisch aus Kapitel 3 zu übernehmen.